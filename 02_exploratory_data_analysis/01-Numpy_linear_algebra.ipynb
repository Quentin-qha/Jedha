{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEfQKpk2Hz33"
   },
   "source": [
    "# Numpy and linear algebra ü§∏\n",
    "\n",
    "NumPy is the fundamental package for scientific computing in Python. This library provides a multidimensional array object that allows to represent vectors, matrices and tensors, and an assortment of routines for fast operations on arrays : mathematical, logical, shape manipulation, sorting, selecting, basic linear algebra, basic statistical operations, random simulation and much more.\n",
    "\n",
    "In this course, you will learn how to use Numpy and apply what you learnt from the [Linear Algebra](https://app.jedha.co/course/linear-algebra-basics/linear-algebra-cheatsheet) prepwork :\n",
    "* Create vectors, matrices and tensors with Numpy arrays\n",
    "* Perform basic operations on vectors and matrices\n",
    "  * Addition, substraction, scaling\n",
    "  * Norm, dot product of vectors\n",
    "  * Matrix transpose\n",
    "  * Matrix multiplication\n",
    "* Illustrate linear algebra concepts:\n",
    "  * Inverse of a matrix\n",
    "  * Orthogonality\n",
    "  * Eigenvectors, eigenvalues of a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PIvM2kDL7WS"
   },
   "source": [
    "# Numpy & Linear Algebra ü§π‚Äç‚ôÇÔ∏è\n",
    "\n",
    "This lecture follows the structure of the [Linear Algebra](https://app.jedha.co/course/linear-algebra-basics/linear-algebra-cheatsheet) prepwork. All the notions introduced in the prepwork will be illustrated with Numpy objects. Let's start by getting familiar with Numpy's most important class : Numpy arrays !\n",
    "\n",
    " ‚òùÔ∏è You're supposed to be already familiar with the definitions and properties that are mentionned in the prepwork. This lecture will focus on showing related examples with numpy.\n",
    "\n",
    "## Using Python libraries\n",
    "\n",
    "### What's a library ?\n",
    "\n",
    "Now that you have an idea of what object-oriented programming is, using libraries shouldn't seem too complex. Indeed, a library is a module in which there are several classes that you can use at your discretion.\n",
    "\n",
    "You have probably seen or heard of _pandas, numpy and scikit-learn._ These are three very popular libraries among data scientists, which provide classes that are toolboxes for data manipulation and machine learning.\n",
    "\n",
    "\n",
    "#### How to import a library ?\n",
    "\n",
    "\n",
    "```python\n",
    "import module_name\n",
    "```\n",
    "\n",
    "\n",
    "It's as simple as that to import a library. However, by doing this you have imported your entire library at once. Sometimes it is not useful or even counterproductive to do this because it will slow down your code considerably.\n",
    "\n",
    "As a result, you often decide to import only one class of the module. This is done in the following way:\n",
    "\n",
    "\n",
    "```python\n",
    "from module_name import class_name\n",
    "```\n",
    "\n",
    "\n",
    "#### How to use a library ?\n",
    "\n",
    "A library contains classes definitions (with their attributes and methods) that you can use in your own code. To declare an instance of a class from a library, you can proceed as follow :\n",
    "\n",
    "```python\n",
    "import library_name\n",
    "class_instance = library_name.class_name()\n",
    "```\n",
    "\n",
    "#### Read the documentation !\n",
    "\n",
    "One last thing to understand: there are a lot of different libraries and they don't work the same way. You will have to refer to the documentation of the library in question for more information. In the course of the program, we will see a lot of different libraries so that you can become familiar with the concept.\n",
    "\n",
    "\n",
    "## Numpy arrays\n",
    "\n",
    "An array is a central data structure of the NumPy library. It is a grid of values and it contains information about the raw data, how to locate an element, and how to interpret an element. It has a grid of elements that can be indexed in various ways. The elements are all of the same type, referred to as the array **dtype**.\n",
    "\n",
    "The **rank** of the array is the number of dimensions. A 1D-array represents a vector, a 2D-array is a matrix. In general, an array of rank N represents a N-dimensional tensor.\n",
    "\n",
    "The **shape** of the array is a tuple of integers giving the size of the array along each dimension.\n",
    "\n",
    "One way we can initialize NumPy arrays is from Python lists, using nested lists for two- or higher-dimensional data. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sd_i_iZ4M0sW"
   },
   "outputs": [],
   "source": [
    "# import the library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnLgUyC2L7-_",
    "outputId": "ad81f2e1-3be0-4fc6-99bc-9cf28b00a126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a numpy array representing a vector of 5 integer elements\n",
    "A = np.array([1,2,3,4,5], dtype=int)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkKAQRQjM6B1",
    "outputId": "ae8f9b72-9e55-4b78-d487-22942cbeb543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# If you don't specify the dtype, numpy will deduce it from the values present in the table\n",
    "my_array = np.array([1,2,3,4])\n",
    "print(my_array)\n",
    "print(my_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OY34aODNFTI",
    "outputId": "92c13b82-39db-4033-cf73-dbd9b11f1bbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "Shape of the matrix :  (2, 3)\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]]\n",
      "Shape of the tensor :  (2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# You can use nested lists to initialize a matrix or a tensor of a higher rank:\n",
    "my_matrix = np.array([[1,2,3],\n",
    "                      [4,5,6]])\n",
    "print(my_matrix)\n",
    "print(\"Shape of the matrix : \", my_matrix.shape)\n",
    "\n",
    "my_tensor = np.array([[[1,2,3],\n",
    "                       [4,5,6]],\n",
    "                       [[7,8,9],\n",
    "                       [10,11,12]]])\n",
    "print(my_tensor)\n",
    "print(\"Shape of the tensor : \", my_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U0cVoZwN5P1"
   },
   "source": [
    "Now we know how to create numpy arrays, let's review the linear algebra prepwork by illustrating each notion with numpy examples !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eajXpIjtHf9E"
   },
   "source": [
    "## Definitions and notations ‚úçÔ∏è\n",
    "\n",
    "Let $n$ be a positive integer and let $\\mathbb{R}$ denote the set of all real numbers.\n",
    "\n",
    "### Vector\n",
    "\n",
    "A vector $\\vec{v} \\in \\mathbb{R}^n$ is a list of $n$ real numbers (also called \"$n$-tuple of real numbers\"). The notation $\\in S$ is read \"element of S\".\n",
    "\n",
    "### Examples\n",
    "Consider a vector that has three components $v_1$, $v_2$ and $v_3$:\n",
    "\n",
    "$$\n",
    "\\vec{v} = \\begin{bmatrix}\n",
    "v_1 \\\\\n",
    "v_2 \\\\\n",
    "v_3\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "5\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^3\n",
    "$$\n",
    "\n",
    "where $v_1$, $v_2$ and $v_3$ can take any value in the set of real numbers.\n",
    "\n",
    "The coordinates $v_1$ $v_2$ and $v_3$ can be used to represent the vector graphically:\n",
    "\n",
    "<img src=\"https://julie-online-courses.s3.eu-west-3.amazonaws.com/Linear_algebra/vector.png\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InX-Fa4Vthwp",
    "outputId": "f8e62716-6f15-46ae-c52e-c903819235fa"
   },
   "source": [
    "# Representation of vector v in numpy\n",
    "v_vec = np.array([2, 3, 5])\n",
    "print(v_vec)\n",
    "print(\"Shape of v: \", v_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFzqKCuKHf9F"
   },
   "source": [
    "### Matrix\n",
    "\n",
    "A matrix $A \\in \\mathbb{R}^{n \\times m}$ is a rectangular array of real number with $n$ rows and $m$ columns.\n",
    "\n",
    "#### Example\n",
    "\n",
    "For example, a $3 \\times 2$ matrix $A$ looks like this:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "-1 & 3 \\\\\n",
    "0 & 4\n",
    "\\end{bmatrix} \\in \\mathbb{R^{3 \\times 2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XhNCS4-t5PG",
    "outputId": "7678cfa9-6fcd-48ed-9ec9-dd7b03afe6e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [-1  3]\n",
      " [ 0  4]]\n",
      "Shape of A:  (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Representation of A\n",
    "A_mat = np.array([[1, 2],\n",
    "                  [-1, 3],\n",
    "                  [0, 4]])\n",
    "print(A_mat)\n",
    "print(\"Shape of A: \", A_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCJfyz5rwnnN"
   },
   "source": [
    "## Operations with vectors and matrices ü§π\n",
    "\n",
    "### Vector operations\n",
    "\n",
    "Let $\\vec{u}$ and $\\vec{v}$ be two vectors:\n",
    "\n",
    "$$\n",
    "\\vec{u} = \\begin{bmatrix}\n",
    "u_1 \\\\\n",
    "u_2 \\\\\n",
    "u_3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec{v} = \\begin{bmatrix}\n",
    "v_1 \\\\\n",
    "v_2 \\\\\n",
    "v_3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The operations we can perform on $\\vec{u}$ and $\\vec{v}$ are: addition, subtraction, scaling, norm (length), and dot product.\n",
    "\n",
    "#### Addition\n",
    "\n",
    "$$\n",
    "\\vec{u} + \\vec{v} = \\begin{bmatrix}\n",
    "u_1 + v_1 \\\\\n",
    "u_2 + v_2 \\\\\n",
    "u_3 + v_3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### Substraction\n",
    "\n",
    "$$\n",
    "\\vec{u} - \\vec{v} = \\begin{bmatrix}\n",
    "u_1 - v_1 \\\\\n",
    "u_2 - v_2 \\\\\n",
    "u_3 - v_3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### Scaling\n",
    "\n",
    "$$\n",
    "a\\vec{u} = \\begin{bmatrix}\n",
    "au_1 \\\\\n",
    "au_2 \\\\\n",
    "au_3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where a is any real number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9zsdPlAwnc3",
    "outputId": "c4cd3cc2-138d-42df-f134-15ecfadae7f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector u:\n",
      "[6 0 2]\n",
      "vector v:\n",
      "[-1 -2  3]\n",
      "\n",
      "addition of u and v: \n",
      "[ 5 -2  5]\n",
      "\n",
      "substraction of u and v: \n",
      "[ 7  2 -1]\n",
      "\n",
      "scaling of u by a factor 3: \n",
      "[18  0  6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example with numpy\n",
    "u_vec = np.array([6, 0, 2])\n",
    "v_vec = np.array([-1, -2, 3])\n",
    "print(\"vector u:\")\n",
    "print(u_vec)\n",
    "print(\"vector v:\")\n",
    "print(v_vec)\n",
    "print()\n",
    "\n",
    "# The operators +, - and * work with numpy arrays !\n",
    "print(\"addition of u and v: \")\n",
    "print(u_vec + v_vec)\n",
    "print()\n",
    "\n",
    "print(\"substraction of u and v: \")\n",
    "print(u_vec - v_vec)\n",
    "print()\n",
    "\n",
    "print(\"scaling of u by a factor 3: \")\n",
    "print(3*u_vec)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naZ4shGawnPd"
   },
   "source": [
    "#### Norm\n",
    "\n",
    "The norm of a vector represents its length and is defined by:\n",
    "\n",
    "$$\n",
    "\\Vert \\vec{u} \\Vert = \\sqrt{u_1^2 + u_2^2 + u_3^2}\n",
    "$$\n",
    "\n",
    "#### Dot product\n",
    "\n",
    "The dot product between two vectors is:\n",
    "\n",
    "$$\n",
    "\\vec{u} \\cdot \\vec{v} = u_1 v_1 + u_2 v_2 + u_3 v_3\n",
    "$$\n",
    "\n",
    "The dot product can also be described in terms of the angle $\\theta$ between the two vectors:\n",
    "\n",
    "$$\n",
    "\\vec{u} \\cdot \\vec{v} = \\Vert \\vec{u} \\Vert \\Vert \\vec{v} \\Vert \\mathrm{cos} \\theta\n",
    "$$\n",
    "\n",
    "<img src=\"https://julie-online-courses.s3.eu-west-3.amazonaws.com/Linear_algebra/vector_operations.jpg\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvuBio0fyd35"
   },
   "source": [
    "For more advanced operations on vectors and matrices, such as computing the norm of a vector, you'll find the [linalg](https://numpy.org/doc/stable/reference/routines.linalg.html) module in numpy (\"linalg\" stands for \"linear algebra\" üòâ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcuIrdXfwnCj",
    "outputId": "b9e5769b-9f8e-4fe0-dade-ecafd8ddcff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector u:\n",
      "[6 0 2]\n",
      "vector v:\n",
      "[-1 -2  3]\n",
      "\n",
      "-- norm of u and v --\n",
      "Norm of u:\n",
      "6.324555320336759\n",
      "Norm of v:\n",
      "3.7416573867739413\n",
      "\n",
      "-- dot-product of u and v --\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example with numpy\n",
    "print(\"vector u:\")\n",
    "print(u_vec)\n",
    "print(\"vector v:\")\n",
    "print(v_vec)\n",
    "print()\n",
    "\n",
    "# Norm of vectors\n",
    "print(\"-- norm of u and v --\")\n",
    "print(\"Norm of u:\")\n",
    "print(np.linalg.norm(u_vec)) # use norm function from the linalg module\n",
    "print(\"Norm of v:\")\n",
    "print(np.linalg.norm(v_vec))\n",
    "print()\n",
    "\n",
    "# Dot-product of u and v\n",
    "print(\"-- dot-product of u and v --\")\n",
    "print(u_vec.dot(v_vec))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yVGWWWNwmv6"
   },
   "source": [
    "üí° We just demonstrated that the dot product of u and v is equal to 0 ! This is a special case that occurs when $\\cos(\\theta) = 0$, where $\\theta$ is the angle between the two vectors. We'll investigate this special case more in details later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRXT1dJo30cY"
   },
   "source": [
    "### Matrix operations\n",
    "\n",
    "We denote by $A$ the matrix as a whole and refer to its entries as $a_{ij}$.\n",
    "The mathematical operations defined for matrices are the following:\n",
    "\n",
    "#### Addition\n",
    "\n",
    "$$\n",
    "C = A + B \\iff c_{ij} = a_{ij} + b_{ij}\n",
    "$$\n",
    "\n",
    "In other words, you just have to perform the addition element-wise. For example:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a_{11} & \\color{blue}{a_{12}} & a_{13} \\\\\n",
    "a_{21} & a_{22} & \\color{green}{a_{23}}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "b_{11} & \\color{blue}{b_{12}} & b_{13} \\\\\n",
    "b_{21} & b_{22} & \\color{green}{b_{23}}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{11} + b_{11} & \\color{blue}{a_{12} + b_{12}} & a_{13} + b_{13} \\\\\n",
    "a_{21} + b_{21} & a_{22} + b_{22} & \\color{green}{a_{23} + b_{23}}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### Substraction\n",
    "\n",
    "As addition, matrix substraction can be performed element-wise:\n",
    "\n",
    "$$\n",
    "C = A - B \\iff c_{ij} = a_{ij} - b_{ij}\n",
    "$$\n",
    "\n",
    "For example:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a_{11} & \\color{blue}{a_{12}} & a_{13} \\\\\n",
    "a_{21} & a_{22} & \\color{green}{a_{23}}\n",
    "\\end{bmatrix}\n",
    "-\n",
    "\\begin{bmatrix}\n",
    "b_{11} & \\color{blue}{b_{12}} & b_{13} \\\\\n",
    "b_{21} & b_{22} & \\color{green}{b_{23}}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{11} - b_{11} & \\color{blue}{a_{12} - b_{12}} & a_{13} - b_{13} \\\\\n",
    "a_{21} - b_{21} & a_{22} - b_{22} & \\color{green}{a_{23} - b_{23}}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### Scaling\n",
    "\n",
    "Let $\\alpha$ be any real number, then:\n",
    "\n",
    "$$\n",
    "C = \\alpha A \\iff c_{ij} = \\alpha a_{ij}\n",
    "$$\n",
    "\n",
    "For example:\n",
    "\n",
    "$$\n",
    "\\color{blue}\\alpha \\begin{bmatrix}\n",
    "a_{11} & a_{12} & a_{13} \\\\\n",
    "a_{21} & a_{22} & a_{23}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\color{blue}\\alpha a_{11} & \\color{blue}\\alpha a_{12} & \\color{blue}\\alpha a_{13} \\\\\n",
    "\\color{blue}\\alpha a_{21} & \\color{blue}\\alpha a_{22} & \\color{blue}\\alpha a_{23}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_xuT8UkwmX5",
    "outputId": "da70964a-a16a-4c0c-bae1-d122d22a1349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix A:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "matrix B:\n",
      "[[10 10 10]\n",
      " [20 20 20]\n",
      " [30 30 30]]\n",
      "\n",
      "Addition of A and B:\n",
      "[[11 12 13]\n",
      " [24 25 26]\n",
      " [37 38 39]]\n",
      "\n",
      "Substraction of A and B:\n",
      "[[ -9  -8  -7]\n",
      " [-16 -15 -14]\n",
      " [-23 -22 -21]]\n",
      "\n",
      "Scaling of A by a factor 2:\n",
      "[[ 2  4  6]\n",
      " [ 8 10 12]\n",
      " [14 16 18]]\n"
     ]
    }
   ],
   "source": [
    "# Example wih numpy\n",
    "A_mat = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "B_mat = np.array([[10, 10, 10],\n",
    "                  [20, 20, 20],\n",
    "                  [30, 30, 30]])\n",
    "\n",
    "print(\"matrix A:\")\n",
    "print(A_mat)\n",
    "print(\"matrix B:\")\n",
    "print(B_mat)\n",
    "print()\n",
    "\n",
    "print(\"Addition of A and B:\")\n",
    "print(A_mat + B_mat) # the + operator also works for any rank of numpy array : vectors, matrices ans tensors !\n",
    "print()\n",
    "\n",
    "print(\"Substraction of A and B:\")\n",
    "print(A_mat - B_mat) # same for the - operator\n",
    "print()\n",
    "\n",
    "print(\"Scaling of A by a factor 2:\")\n",
    "print(2*A_mat) # same for the * operator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TZkgs6LHf9I"
   },
   "source": [
    "#### Matrix product\n",
    "\n",
    "The product of matrices $A \\in \\mathbb{R}^{n \\times m}$ and $\\in \\mathbb{R}^{m \\times l}$ is another matrix $C \\in \\mathbb{R}^{n \\times l}$ given by the formula :\n",
    "\n",
    "$$\n",
    "C = AB \\iff c_{ij} = \\sum\\limits_{k=1}^n{a_{ik}b_{kj}}\n",
    "$$\n",
    "\n",
    "This one is not easy to understand at first glance üßê ! Let's consider an example:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\color{blue}{a_{11}} & \\color{blue}{a_{12}} \\\\\n",
    "\\color{green}{a_{21}} & \\color{green}{a_{22}} \\\\\n",
    "a_{31} & a_{32}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\color{green}{b_{11}} & \\color{blue}{b_{12}} \\\\\n",
    "\\color{green}{b_{21}} & \\color{blue}{b_{22}}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{11}b_{11} + a_{12}b_{21} & \\color{blue}{a_{11}b_{12} + a_{12}b_{22}} \\\\\n",
    "\\color{green}{a_{21}b_{11} + a_{22}b_{21}} & a_{21}b_{12} + a_{22}b_{22} \\\\\n",
    "a_{31}b_{11} + a_{32}b_{21} & a_{31}b_{12} + a_{32}b_{22}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The colors are here to highlight the lines/columns of matrices $A$ and $B$ that are used to compute a given entry of $C$. The general rule is that for entry $c_{ij}$, you'll use the entries of the i-th line of A and the j-th column of B. As a consequence, the matrix product $AB$ is defined only if the number of rows in $B$ is equal to the number of columns in $A$.\n",
    "\n",
    "‚òùÔ∏è Note that matrix product is not a commutative operation : $AB \\ne BA$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-emVsr06j8r",
    "outputId": "f7554bff-e841-4aa5-f5a9-c9526cbffbac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix A:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "matrix B:\n",
      "[[10 10 10]\n",
      " [20 20 20]\n",
      " [30 30 30]]\n",
      "\n",
      "-- With @ operator --\n",
      "Matrix product AB: \n",
      "[[140 140 140]\n",
      " [320 320 320]\n",
      " [500 500 500]]\n",
      "\n",
      "Matrix product BA: \n",
      "[[120 150 180]\n",
      " [240 300 360]\n",
      " [360 450 540]]\n",
      "\n",
      "-- With .dot function --\n",
      "Matrix product AB: \n",
      "[[140 140 140]\n",
      " [320 320 320]\n",
      " [500 500 500]]\n",
      "\n",
      "Matrix product BA: \n",
      "[[120 150 180]\n",
      " [240 300 360]\n",
      " [360 450 540]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example with numpy\n",
    "print(\"matrix A:\")\n",
    "print(A_mat)\n",
    "print(\"matrix B:\")\n",
    "print(B_mat)\n",
    "print()\n",
    "\n",
    "# The @ operator represents matrix multiplication\n",
    "print(\"-- With @ operator --\")\n",
    "print(\"Matrix product AB: \")\n",
    "print(A_mat @ B_mat)\n",
    "print()\n",
    "print(\"Matrix product BA: \")\n",
    "print(B_mat @ A_mat)\n",
    "print()\n",
    "\n",
    "# Another way of computing matrix multiplication is to use the dot product !\n",
    "print(\"-- With .dot function --\")\n",
    "print(\"Matrix product AB: \")\n",
    "print(A_mat.dot(B_mat))\n",
    "print()\n",
    "print(\"Matrix product BA: \")\n",
    "print(B_mat.dot(A_mat))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDMYCi8k7kfN"
   },
   "source": [
    "### Matrix-vector product\n",
    "\n",
    "The matrix-vector product is an important special case of the matrix-matrix product. For example, the product of a $3 \\times 2$ matrix $C$ and a $2 \\times 1$ vector $\\vec{x}$ results in a $3 \\times 1$ vector $\\vec{y} = C \\vec{x}$ given by:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "\\color{blue}{y_2} \\\\\n",
    "y_3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "c_{11} & c_{12} \\\\\n",
    "\\color{blue}{c_{21}} & \\color{blue}{c_{22}} \\\\\n",
    "c_{31} & c_{32}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\color{green}{x_{1}} \\\\\n",
    "\\color{green}{x_{2}}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "c_{11}x_{1} + c_{12}x_{2} \\\\\n",
    "\\color{blue}{c_{21}}\\color{green}{x_{1}} + \\color{blue}{c_{22}}\\color{green}{x_{2}} \\\\\n",
    "c_{31}x_{1} + c_{32}x_{2}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvx1gyM07k37",
    "outputId": "7671469a-b922-43e6-e744-e912967009b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix C of shape  (3, 2)\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "vector x of shape  (2,)\n",
      "[ 5 -2]\n",
      "\n",
      "The product Cx gives another vector y of shape  (3,)\n",
      "[ 1  7 13]\n"
     ]
    }
   ],
   "source": [
    "# Example with numpy\n",
    "C_mat = np.array([[1, 2],\n",
    "                 [3, 4],\n",
    "                  [5, 6]])\n",
    "x_vec = np.array([5, -2])\n",
    "\n",
    "print(\"matrix C of shape \", C_mat.shape)\n",
    "print(C_mat)\n",
    "print()\n",
    "print(\"vector x of shape \", x_vec.shape)\n",
    "print(x_vec)\n",
    "print()\n",
    "\n",
    "# Compute matrix-vector product\n",
    "y_vec = C_mat @ x_vec\n",
    "print(\"The product Cx gives another vector y of shape \", y_vec.shape)\n",
    "print(y_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdFuBiqUwkXf"
   },
   "source": [
    "## Matrix transpose\n",
    "\n",
    "The transpose of a matrix A, denoted $A^\\intercal$ is computed as follows:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\color{blue}{\\alpha_{1}} & \\color{blue}{\\alpha_{2}} & \\color{blue}{\\alpha_{3}} \\\\\n",
    "\\color{green}{\\beta_{1}} & \\color{green}{\\beta_{2}} & \\color{green}{\\beta_{3}}\n",
    "\\end{bmatrix}^\\intercal\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\color{blue}{\\alpha_{1}} & \\color{green}{\\beta_{1}} \\\\\n",
    "\\color{blue}{\\alpha_{2}} & \\color{green}{\\beta_{2}} \\\\\n",
    "\\color{blue}{\\alpha_{3}} & \\color{green}{\\beta_{3}}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In other words, the transpose is obtained by swaping the rows and the columns.\n",
    "\n",
    "‚òùÔ∏è A very useful property : $(AB)^\\intercal = B^\\intercal A^\\intercal$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDfqgj1kwloV",
    "outputId": "77c40141-0d5c-4640-8841-ae39cdbe0994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix A:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Transpose of A:\n",
      "[[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n",
      "\n",
      "matrix B:\n",
      "[[10 10 10]\n",
      " [20 20 20]\n",
      " [30 30 30]]\n",
      "Transpose of B:\n",
      "[[10 20 30]\n",
      " [10 20 30]\n",
      " [10 20 30]]\n",
      "\n",
      "Tranpose(AB):\n",
      "[[140 320 500]\n",
      " [140 320 500]\n",
      " [140 320 500]]\n",
      "\n",
      "Tranpose(B) @ Tranpose(A):\n",
      "[[140 320 500]\n",
      " [140 320 500]\n",
      " [140 320 500]]\n"
     ]
    }
   ],
   "source": [
    "# Example with numpy\n",
    "print(\"matrix A:\")\n",
    "print(A_mat)\n",
    "print(\"Transpose of A:\")\n",
    "print(A_mat.T) # .T allows to transpose a numpy array\n",
    "print()\n",
    "print(\"matrix B:\")\n",
    "print(B_mat)\n",
    "print(\"Transpose of B:\")\n",
    "print(B_mat.T)\n",
    "print()\n",
    "\n",
    "print(\"Tranpose(AB):\")\n",
    "print((A_mat @ B_mat).T)\n",
    "print()\n",
    "\n",
    "print(\"Tranpose(B) @ Tranpose(A):\")\n",
    "print(B_mat.T @ A_mat.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtGZoOqzHf9H"
   },
   "source": [
    "## Identity matrix\n",
    "\n",
    "The identity matrix, noted $\\mathbb{1}$, is a particular matrix such that, if you multiply any vector $\\vec{v}$ by $\\mathbb{1}$, the vector will remain unchanged:\n",
    "\n",
    "$$\n",
    "\\mathbb{1} \\vec{v} = \\vec{v}\n",
    "$$\n",
    "\n",
    "The identity matrix is simply composed of ones on the diagonal and zeros everywhere else. For example, in $\\mathbb{R}^3$:\n",
    "\n",
    "$$\n",
    "\\mathbb{1} = \\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "NB : At this point of the lecture, you don't yet **how** to compute a matrix-vector multiplication, but don't worry, it will come soon üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XhEdwnuvk15",
    "outputId": "b548f40e-9f84-437e-f040-c078eea66fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity matrix I: \n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "matrix A:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "IA:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "AI:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# identity matrix in numpy\n",
    "id_mat = np.identity(3, dtype = 'int')\n",
    "print(\"identity matrix I: \")\n",
    "print(id_mat)\n",
    "print(\"matrix A:\")\n",
    "print(A_mat)\n",
    "print()\n",
    "\n",
    "print(\"IA:\")\n",
    "print(id_mat @ A_mat)\n",
    "print(\"AI:\")\n",
    "print(A_mat @ id_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kTr_6CZHf9H"
   },
   "source": [
    "## Inverse of a matrix\n",
    "\n",
    "Let's consider a square matrix $A \\in \\mathbb{R}^{n \\times n}$. The inverse of $A$, noted $A^{-1}$ is the matrix such that:\n",
    "\n",
    "$$\n",
    "A^{-1}A = A A^{-1} = \\mathbb{1}\n",
    "$$\n",
    "\n",
    "In other words, $A^{-1}$ is the matrix that \"*undoes*\" the effect of $A$, because if you apply $A^{-1}$ after $A$ on any vector $\\vec{v}$, it will remain unchanged:\n",
    "\n",
    "$$\n",
    "A^{-1}A \\vec{v} = \\mathbb{1} \\vec{v} = \\vec{v}\n",
    "$$\n",
    "\n",
    "### Finding the inverse of a matrix\n",
    "\n",
    "There exist several methods to find the inverse of a matrix : the most famous is the [Gauss-Jordan pivot](https://www.youtube.com/watch?v=cJg2AuSFdjw). However, we won't cover it in this lecture, as it is not fundamental for *understanding* the concepts that are necessary for Machine Learning. As a data specialist, if you need to compute the inverse of a matrix, you'll use numpy's `linalg.inv` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ZNzvtLSBq55",
    "outputId": "17c10440-37b7-4945-8004-1e6a151b0655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix D:\n",
      "[[ 3  0  2]\n",
      " [ 2  0 -2]\n",
      " [ 0  1  1]]\n",
      "\n",
      "Inverse of D:\n",
      "[[ 0.2  0.2  0. ]\n",
      " [-0.2  0.3  1. ]\n",
      " [ 0.2 -0.3 -0. ]]\n",
      "\n",
      "Let's check the matrix product of D with its inverse:\n",
      "[[ 1.  0. -0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "\n",
      "[[ 1.  0.  0.]\n",
      " [-0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Example with numpy\n",
    "print(\"matrix D:\")\n",
    "D_mat = np.array([[3, 0, 2],\n",
    "                  [2, 0, -2],\n",
    "                  [0, 1, 1]], dtype = 'int')\n",
    "print(D_mat)\n",
    "print()\n",
    "\n",
    "print(\"Inverse of D:\")\n",
    "D_mat_inv = np.linalg.inv(D_mat)\n",
    "print(D_mat_inv)\n",
    "print()\n",
    "\n",
    "print(\"Let's check the matrix product of D with its inverse:\")\n",
    "print((D_mat_inv @ D_mat).round(2))\n",
    "print()\n",
    "print((D_mat @ D_mat_inv).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk2ps1e7HcEU"
   },
   "source": [
    "## Collinearity and orthogonality üìèüìê\n",
    "\n",
    "### Collinearity of vectors\n",
    "\n",
    "Two vectors $\\vec{v_1}$ and $\\vec{v_2}$ are collinear if their geometric representations are \"parallel\". Mathematically, there exists a real number $c$ such that:\n",
    "\n",
    "$$\n",
    "\\vec{v_1} = c \\vec{v_2}\n",
    "$$\n",
    "\n",
    "<img src=\"https://julie-online-courses.s3.eu-west-3.amazonaws.com/Linear_algebra/collinearity.png\" width=\"100\"/>\n",
    "\n",
    "### Multicollinearity\n",
    "\n",
    "There's an extension of the concept of collinearity for three vectors or more : Let's consider three vectors $\\vec{u}$, $\\vec{v}$ and $\\vec{w}$. We say there's multicollinearity if there exist real numbers $a$ and $b$ such that:\n",
    "\n",
    "$$\n",
    "\\vec{w} = a\\vec{u} + b\\vec{v}\n",
    "$$\n",
    "\n",
    "Geometrically, it means that the vector $\\vec{w}$ can be obtained by following paths in the directions of $\\vec{u}$ and $\\vec{v}$.\n",
    "\n",
    "<img src=\"https://julie-online-courses.s3.eu-west-3.amazonaws.com/Linear_algebra/multicollinearity.png\" width=\"200\"/>\n",
    "\n",
    "### Orthogonality of vectors\n",
    "\n",
    "We say two vectors $\\vec{u}$ and $\\vec{v}$ are orthogonal if the angle between them is $\\theta = 90¬∞$.\n",
    "\n",
    "The dot product of orthogonal vectors is zero:\n",
    "\n",
    "$$\n",
    "\\vec{u} \\cdot \\vec{v} = \\Vert \\vec{u} \\Vert \\Vert \\vec{v} \\Vert \\mathrm{cos}(90¬∞) = 0\n",
    "$$\n",
    "\n",
    "<img src=\"https://julie-online-courses.s3.eu-west-3.amazonaws.com/Linear_algebra/orthogonality.png\" width=\"200\"/>\n",
    "\n",
    "üí° Remember our vectors $\\vec{u}$ and $\\vec{v}$ in the previous examples ? We noticed that the dot product was zero, this means that $\\vec{u}$ and $\\vec{v}$ are orthogonal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrKbG2U7Hf9K"
   },
   "source": [
    "### Orthogonality of matrices\n",
    "\n",
    "A matrix $U \\in \\mathbb{R}^{m \\times n}$ is orthogonal if $U^\\intercal U = \\mathbb{1}$.\n",
    "\n",
    "#### Properties of orthogonal matrices\n",
    "\n",
    "* If $U$ is square and orthogonal, $U^\\intercal U = U U^\\intercal = \\mathbb{1}$ and $U^{-1} = U^\\intercal$\n",
    "* The product of two orthogonal matrices $U$ and $V$ is also an orthogonal matrix : $(UV)^\\intercal (UV) = V^\\intercal U^\\intercal UV = V^\\intercal V = \\mathbb{1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z914pMAqIx_1",
    "outputId": "dbdbb719-ad1d-4b97-f0b7-328e30541146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix U:\n",
      "[[ 0.66666667 -0.66666667  0.33333333]\n",
      " [ 0.33333333  0.66666667  0.66666667]\n",
      " [ 0.66666667  0.33333333 -0.66666667]]\n",
      "\n",
      "Tranpose of matrix U:\n",
      "[[ 0.66666667  0.33333333  0.66666667]\n",
      " [-0.66666667  0.66666667  0.33333333]\n",
      " [ 0.33333333  0.66666667 -0.66666667]]\n",
      "\n",
      "Matrix product of tranpose(U) and U:\n",
      "[[ 1. -0.  0.]\n",
      " [-0.  1. -0.]\n",
      " [ 0. -0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Example with numpy\n",
    "U_mat = np.array([[2/3, -2/3, 1/3],\n",
    "                  [1/3, 2/3, 2/3],\n",
    "                  [2/3, 1/3, -2/3]])\n",
    "print(\"Matrix U:\")\n",
    "print(U_mat)\n",
    "print()\n",
    "\n",
    "print(\"Tranpose of matrix U:\")\n",
    "print(U_mat.T)\n",
    "print()\n",
    "\n",
    "print(\"Matrix product of tranpose(U) and U:\")\n",
    "print((U_mat.T @ U_mat).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rMXnMjqHf9L"
   },
   "source": [
    "## Systems of Linear Equations : Matrix representation üìù\n",
    "\n",
    "Suppose we're asked to solve the following system of equations:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "      1x_1 + 2x_2 = 5 \\\\\n",
    "      3x_1 + 9x_2 = 21\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "One approach for solving this system (that's to say: finding the values of $x_1$ and $x_2$) is to consider its matrix representation. Indeed, using the definition of the matrix vector product, we can express this system as a matrix equation:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 9\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "5 \\\\\n",
    "21\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This matrix equation has the form $A \\vec{x} = \\vec{b}$, where A is a $2 \\times 2$ matrix, $\\vec{x}$ is the vector of unknowns, and $\\vec{b}$ is a vector of constants:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 9\n",
    "\\end{bmatrix} \\\\\n",
    "\\vec{x} = \\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{bmatrix} \\\\\n",
    "\\vec{b} = \\begin{bmatrix}\n",
    "5 \\\\\n",
    "21\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "To solve this matrix equation, we can use the definition of the inverse of a matrix:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A \\vec{x} = \\vec{b} \\\\\n",
    "\\iff A^{-1} A \\vec{x} = A^{-1}\\vec{b} \\\\\n",
    "\\iff \\mathbb{1} \\vec{x} = A^{-1}\\vec{b} \\\\\n",
    "\\iff \\vec{x} = A^{-1}\\vec{b}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In other words, to find the values of $x_1$ $x_2$, we just have to know what is the inverse $A^{-1}$. Let's assume we can use some programming library, and we were able to determine that $A^{-1} = \\begin{bmatrix} 3 & -\\frac{2}{3} \\\\ -1 & \\frac{1}{3} \\end{bmatrix}$. Now, we just have to compute the matrix-vector product $A^{-1} \\vec{b}$:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "3 & -\\frac{2}{3} \\\\\n",
    "-1 & \\frac{1}{3}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "5 \\\\\n",
    "21\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Et voil√†, we just solved the equation üéâ!\n",
    "\n",
    "This can seem tedious if you're not (yet!) familiar with matrix operations, but imagine the case when you want to solve a more complex system with many unknowns $x_1, x_2, x_3, ...$ Actually this method can be quite powerful and it is extensively used in Machine Learning to solve the system of equations necessary to train a model. That's why it is so important ! But don't worry, in practice, you will never compute the different steps by hand, your computer will do it for you üòå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIsphhduLh_1",
    "outputId": "a04f3eb4-0217-4234-8312-0844134211f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "[[1 2]\n",
      " [3 9]]\n",
      "Vector b:\n",
      "[ 5 21]\n",
      "\n",
      "-- Method 1 --\n",
      "Solution of equation Ax = b:\n",
      "x =  [1. 2.]\n",
      "\n",
      "-- Method 2 --\n",
      "Solution of equation Ax = b:\n",
      "x =  [1. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Example with numpy\n",
    "A_mat = np.array([[1, 2],\n",
    "                  [3, 9]])\n",
    "b_vec = np.array([5, 21])\n",
    "print(\"Matrix A:\")\n",
    "print(A_mat)\n",
    "print(\"Vector b:\")\n",
    "print(b_vec)\n",
    "print()\n",
    "\n",
    "## Method 1\n",
    "print(\"-- Method 1 --\")\n",
    "# Compute inverse of matrix A\n",
    "A_mat_inv = np.linalg.inv(A_mat)\n",
    "# Solve equation\n",
    "x_vec = A_mat_inv @ b_vec\n",
    "print(\"Solution of equation Ax = b:\")\n",
    "print(\"x = \", x_vec)\n",
    "print()\n",
    "\n",
    "## Method 2 : with np.linalg.solve\n",
    "print(\"-- Method 2 --\")\n",
    "x_vec = np.linalg.solve(A_mat, b_vec)\n",
    "print(\"Solution of equation Ax = b:\")\n",
    "print(\"x = \", x_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAuCzZfNHf9L"
   },
   "source": [
    "## Matrix diagonalization üß©\n",
    "\n",
    "### Eigenvectors and eigenvalues\n",
    "\n",
    "The set of eigenvectors of a matrix $A$ is a special set of vectors, noted $\\{\\vec{e_\\lambda} \\}$, for which the action of the matrix is a simple scaling. When a matrix is multiplied by one of its eigenvectors the output is the same eigenvector multiplied by a constant $\\lambda$:\n",
    "\n",
    "$$\n",
    "A \\vec{e_\\lambda} = \\lambda \\vec{e_\\lambda}\n",
    "$$\n",
    "\n",
    "The constant $\\lambda$ is called an *eigenvalue* of A.\n",
    "\n",
    "There exist some technics to determine the eigenvectors and eigenvalues of a matrix, but we won't cover it in this lecture. As for matrix inverse, it is not necessary that you know how to perform this computation, because in practice, your computer will do it for you ! However if you're curious about it, you can check [this link](https://www.youtube.com/watch?v=IdsV0RaC9jM).\n",
    "\n",
    "### Diagonalizable matrix\n",
    "\n",
    "Certain matrices can be written entirely in terms of their eigenvectors and their eigenvalues. Consider the matrix $\\Lambda$ that has the eigenvalues of the matrix $A$ on the diagonal, and the matrix $Q$ constructed from the\n",
    "eigenvectors of $A$ as columns:\n",
    "\n",
    "$$\n",
    "\\Lambda\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "            \\lambda_1 & \\cdots & 0 \\\\\n",
    "            \\vdots & \\ddots & \\vdots \\\\\n",
    "            0 & \\cdots & \\lambda_n \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Q\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "            \\vert &  & \\vert \\\\\n",
    "            \\vec{e_{\\lambda_1}} & \\cdots & \\vec{e_{\\lambda_n}} \\\\\n",
    "            \\vert &  & \\vert\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then, because we can write $AQ= Q \\Lambda$:\n",
    "\n",
    "$$\n",
    "A = Q \\Lambda Q^{-1}\n",
    "$$\n",
    "\n",
    "Matrices that can be written this way are called diagonalizable. Many Machine Learning algorithms, such as *Principal Component Analysis* are built on matrix diagonalization ! You'll have the opportunity to dive deeper into this concept if you follow the Fullstack track at Jedha ü§∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmNwNrQWM8ia",
    "outputId": "4a551425-292f-4a1f-a405-85bc9dcbfda0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "[[ 3  4 -2]\n",
      " [ 1  4 -1]\n",
      " [ 2  6 -1]]\n",
      "\n",
      "Eigenvalues of A:\n",
      "[3. 2. 1.]\n",
      "\n",
      "Eigenvectors of A:\n",
      "[[-0.408  0.     0.707]\n",
      " [-0.408  0.447 -0.   ]\n",
      " [-0.816  0.894  0.707]]\n",
      "\n",
      "Let's check the effect of A on its first eigenvector: \n",
      "[-1.22474487 -1.22474487 -2.44948974]\n",
      "The above is equal to the eigenvector scaled by its eigenvalue (3):\n",
      "[-1.22474487 -1.22474487 -2.44948974]\n"
     ]
    }
   ],
   "source": [
    "# Example with numpy\n",
    "A_mat = np.array([[3, 4, -2],\n",
    "                  [1, 4, -1],\n",
    "                  [2, 6, -1]])\n",
    "print(\"Matrix A:\")\n",
    "print(A_mat)\n",
    "print()\n",
    "\n",
    "eigenvals, eigenvecs = np.linalg.eig(A_mat)\n",
    "print(\"Eigenvalues of A:\")\n",
    "print(eigenvals)\n",
    "print()\n",
    "print(\"Eigenvectors of A:\")\n",
    "print(eigenvecs.round(3))\n",
    "print()\n",
    "\n",
    "print(\"Let's check the effect of A on its first eigenvector: \")\n",
    "print(A_mat @ eigenvecs[:,0])\n",
    "print(\"The above is equal to the eigenvector scaled by its eigenvalue (3):\")\n",
    "print(3*eigenvecs[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uB0sLdvPO9-B"
   },
   "source": [
    "üí°In the code above, we used the syntax `array[:,0]` which is called \"slicing\". You'll learn more about it in next lecture ü§ì"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "naZ4shGawnPd",
    "4rMXnMjqHf9L"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "16196ea7eff63910081d4e10ae1bdb1eb18fd83cb470bb8efbb9fa6b0c724af5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
